import os
import shutil
import snakemake.io
import glob


'''
Adapt your workflow to work to run:
- Fastqc 						(done)
- BWA 							(done)
- SNP calling using bcftools 	(done)
- SNP normalization & filtering (done)
- SNP annotation (using SNPeff) (done)

# TODO:
Every step MUST contain at least one check that the run was succesful - as discussed in class

# TODO:
One check must yield an image - note - this has to be your own code - not a copy of mine or somebody else. 
Be creative.

Document your Snakefile & the code embedded in your Snakefile

Generate a Snakefile report (an actual html file).

Write an extra rule (so not a part of an existing rule) that extracts any SNPs into 
a new VCF file that (according to SNPeff) associates with APP, SOD21 and DYRK1A. 
This VCF file must be called genes.vcf and be in the root of your Snakemake work folder

You must run your snakemake as a SLURM job (using `sbatch`)

Your workflow should run with JUST the snakefile (see points later as well).
So we will grade this assignment by:
- create a work folder
- copy your Snakefile into that folder
- run snakemake with sbatch
- generate the snakemake report

After running the steps described above we expect to see in the snakemake work folder:
A Snakefile report html file
A genes.vcf file with the SNPs associating with the 3 genes.
Bonus Question:

# TODO:
- write an extra rule that creates an image with a heatmap showing how many SNPs 
associate with the three above mentioned genes 
per individual! This image is to be embedded in the Snakefile report. 
		sample 1 sample 2 sample 3
gene 1	6		0		1
gene 2  3		1		0
gene 3  1		4		1
'''

# Chromosome 21 fasta file
genome_db = "/lustre1/project/stg_00079/teaching/hg38_21/chr21.fa"

# Changing dir to $VSC_SCRATCH
#os.chdir("/scratch/leuven/359/vsc35907/")

# Creating working directory if it doest exist already
if not os.path.exists("./snp_call_snakemake"):
	os.mkdir("snp_call_snakemake")
	os.mkdir("snp_call_snakemake/fastq")
else:
	if not os.path.exists("./snp_call_snakemake/fastq"):
		os.mkdir("snp_call_snakemake/fastq")
		
# Changing directory to snp_call_snakemake 
os.chdir("snp_call_snakemake")

# Source directory containing fastq files
source_directory = '/staging/leuven/stg_00079/teaching/1000genomes/'

# Destination directory
destination_directory = './fastq'

# Wildcard pattern to match files
wildcard_pattern = 'HG0???1.*.fq.gz'

# Get list of files matching the wildcard pattern
files_to_copy = glob.glob(os.path.join(source_directory, wildcard_pattern))

# Copy each file to the destination directory (if it does not already exist)
for file_path in files_to_copy:
	if not os.path.exists('./fastq/' + file_path[len(source_directory):]):
		shutil.copy(file_path, destination_directory)

# ----------------- SNAKEMAKE RULES ----------------- #

SAMPLES, = glob_wildcards(destination_directory + "/{sample}.fq.gz")

rule all:
	input:
		fastqc_zip=expand("fastqc_output/{sample}_fastqc.zip", sample=SAMPLES),
		vcf="genes.vcf"

rule gunzip:
	input: 
		"fastq/{sample}.fq.gz"
	output:
		"fastq/{sample}.fq"
	shell:
		'''
		# Unzipping the fastq files
		gunzip {input} || (echo "gunzip failed" && exit 1)
		
		# Checking if fasta file is divisible by 4
		nr_lines=$(wc -l {output} | cut -d " " -f1)
		result=$(($nr_lines % 4))
		if [ $result -ne 0 ]; then
			echo "Error: Fastq file is not divisible by 4"
			#exit 1
		fi
		'''
		

rule fastqc:
	input: 
		fq="fastq/{sample}.fq",
	output: 
		html="fastqc_output/{sample}_fastqc.html",
		fastqc_zip="fastqc_output/{sample}_fastqc.zip",
		summary_txt="fastqc_output/{sample}_fastqc/summary.txt",
		summary_data="fastqc_output/{sample}_fastqc/fastqc_data.txt",
	shell:
		'''
		# Running fastqc on the fastq files
		fastqc -o fastqc_output {input.fq} --extract
		
		# Checking if fastqc produced any FAILs
		if grep -q "FAIL" {output.summary_txt}; then
			echo "Error: FastQC failed for {wildcards.sample}"
			#exit 1
		fi
		'''
		
rule bwa_map:
	input:
		db=genome_db,
		fa="fastq/{sample}.fq"
	output:
		report("mapped_reads/{sample}.bam", category="Bam/Bai files")
	shell:
		'''
		# Mapping the reads to the reference genome
		bwa mem {input} | samtools sort -o {output}
		
		# Quality Control
		#samtools view -H {output}
		#echo "headers ok!"
		#echo "---------"
		#samtools view {output} | head
		#echo "looks like bam"
		#echo "---------"
		#samtools idxstats {output} 
		#echo "reads map to chromosome 21"
		#echo "---------"
		'''
		
		
rule samtools_index:
	input:
		"mapped_reads/{sample}.bam"
	output:
		report("mapped_reads/{sample}.bam.bai", category="Bam/Bai files")
	shell:
		'''
		# Indexing the bam files
		samtools index {input}
		
		# Checks if file exist and has a size greater than 0
		if [ ! -s {output} ]; then
			echo "Error: Index file not created"
			#exit 1
		fi
		'''
        

rule bcftools_call:
	input:
		db = genome_db,
		bam = expand("mapped_reads/{sample}.bam", sample=SAMPLES),
		bai = expand("mapped_reads/{sample}.bam.bai", sample=SAMPLES)
	output:
		report("calls/raw_snps.vcf", category="VCF files")
	shell:
		'''
		# SNP calling using bcftools
		bcftools mpileup -f {input.db} {input.bam} | bcftools call -mv - > {output}
		
		# Checks if file exist and has a size greater than 0
		if [ ! -s {output} ]; then
			echo "Error: raw VCF file not created"
			#exit 1
		fi
		'''


rule snp_cleaning:
	input:
		db = genome_db,
		snps = "calls/raw_snps.vcf"
	output:
		report("calls/clean_snps.vcf", category="VCF files")
	shell:
		'''
		# Decompose, normalize and filter SNPs
		cat {input.snps} | \
		vt decompose - | \
		vt normalize -n -r {input.db} - | \
		vt view -f 'QUAL>20' -h - \
		> {output}
		
		# Checks if file exist and has a size greater than 0
		if [ ! -s {output} ]; then
			echo "Error: clean VCF file not created"
			#exit 1
		fi
		'''
		

rule snp_annotation:
	input:
		snps = "calls/clean_snps.vcf",
		SNPEFF_JAR = "/lustre1/project/stg_00079/teaching/I0U19a_conda_2024/share/snpeff-5.2-0/snpEff.jar"
	output:
		report("calls/annotated_snps.vcf", category="VCF files")
	shell:
		"""
		# Annotate SNPs using SNPeff
		java -Xmx3400m -jar {input.SNPEFF_JAR} eff hg38 -dataDir '/staging/leuven/stg_00079/teaching/snpeff_db' {input.snps} \
		> calls/annotated_snps.vcf
		
		# Checks if file exist and has a size greater than 0
		if [ ! -s {output} ]; then
			echo 'Error: annotated VCF file not created'
			#exit 1 
		fi
		"""

rule genes_of_interest:
	input: 
		"calls/annotated_snps.vcf"
	output: 
		report("genes.vcf", category="VCF files")
	shell:
		"""
		touch {output}

		# Selecting all lines with the words 'APP' or 'SOD1' or 'DYRK1A' in the annotated snps file
		grep -i -E 'APP|SOD1|DYRK1A' {input} | grep -v 'intergenic_region' > {output}
		
		# Checks if file exist and has a size greater than 0
		if [ ! -s {output} ]; then 
			echo 'Error: genes VCF file not created' 

			# exit 1 
		fi

		# Creating heatmap image
		python ./../plot_graphs.py
		"""
		

		


   

# rule fastqc:
#     input:
#         fq="000.fastq/{file}.fastq",
#     output:
#         fastqc_zip="010.fastqc/{file}_fastqc.zip",
#         html="010.fastqc/{file}_fastqc.html",
#         summarydata="010.fastqc/{file}_fastqc/fastqc_data.txt",
#         rep1=report("010.fastqc/{file}_fastqc/Images/per_base_quality.png", category="Fastqc", subcategory="Per base quality"),
#         rep2=report("010.fastqc/{file}_fastqc/Images/per_base_sequence_content.png", category="Fastqc", subcategory="Per base sequence content"),
#         rep3=report("010.fastqc/{file}_fastqc/summary.txt", category="Fastqc", subcategory="Summary text")
#     shell:
#         """
#         echo "Input Fastq: {input.fq} "
#         fastqc -o 010.fastqc {input.fq} --extract

#         ## Q&D testing
#         ## A simple tests would be to see if output files exists
#         ##   - but that is already done by snakemake

#         # So - I'm testing here to see if are there FAILs in the snakemake output. If so
#         # I happy to crash the workflow.
#         if grep FAIL {output.rep3}; then
#             # Found a fail! -
#             echo "FAILED!"
#             # false yields a non-zero return code - which is an error
#             false
#         fi

#         """