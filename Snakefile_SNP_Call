import os
import shutil
import snakemake.io
import glob


'''
Adapt your workflow to work to run:
- Fastqc 						(done)
- BWA 							(done)
- SNP calling using bcftools 	(done)
- SNP normalization & filtering (done)
- SNP annotation (using SNPeff) (done)

# TODO:
Every step MUST contain at least one check that the run was succesful - as discussed in class

One check must yield an image - note - this has to be your own code - not a copy of mine or somebody else. 
Be creative.

Document your Snakefile & the code embedded in your Snakefile

Generate a Snakefile report (an actual html file).

Write an extra rule (so not a part of an existing rule) that extracts any SNPs into 
a new VCF file that (according to SNPeff) associates with APP, SOD21 and DYRK1A. 
This VCF file must be called genes.vcf and be in the root of your Snakemake work folder

You must run your snakemake as a SLURM job (using `sbatch`)

Your workflow should run with JUST the snakefile (see points later as well).
So we will grade this assignment by:
- create a work folder
- copy your Snakefile into that folder
- run snakemake with sbatch
- generate the snakemake report

After running the steps described above we expect to see in the snakemake work folder:
A Snakefile report html file
A genes.vcf file with the SNPs associating with the 3 genes.

Bonus Question:
- write an extra rule that creates an image with a heatmap showing how many SNPs 
associate with the three above mentioned genes 
per individual! This image is to be embedded in the Snakefile report. 
		sample 1 sample 2 sample 3
gene 1	6		0		1
gene 2  3		1		0
gene 3  1		4		1
'''

# Chromosome 21 fasta file
genome_db = "/lustre1/project/stg_00079/teaching/hg38_21/chr21.fa"

# Changing dir to $VSC_SCRATCH
#os.chdir("/scratch/leuven/359/vsc35907/")

# Creating working directory if it doest exist already
if not os.path.exists("./snp_call_snakemake"):
	os.mkdir("snp_call_snakemake")
	os.mkdir("snp_call_snakemake/fastq")
else:
	if not os.path.exists("./snp_call_snakemake/fastq"):
		os.mkdir("snp_call_snakemake/fastq")
		
# Changing directory to snp_call_snakemake 
os.chdir("snp_call_snakemake")

# Source directory containing fastq files
source_directory = '/staging/leuven/stg_00079/teaching/1000genomes/'

# Destination directory
destination_directory = './fastq'

# Wildcard pattern to match files
wildcard_pattern = 'HG0???1.*.fq.gz'

# Get list of files matching the wildcard pattern
files_to_copy = glob.glob(os.path.join(source_directory, wildcard_pattern))

# Copy each file to the destination directory (if it does not already exist)
for file_path in files_to_copy:
	if not os.path.exists('./fastq/' + file_path[len(source_directory):]):
		shutil.copy(file_path, destination_directory)

# Creating an error log file
with open("error_log.txt", "a"):
	os.utime("error_log.txt", None)

# ----------------- SNAKEMAKE RULES ----------------- #

# Get the names of all the samples
SAMPLES, = glob_wildcards(destination_directory + "/{sample}.fq.gz")

rule all:
	input:
		fastqc_zip=expand("fastqc_output/{sample}_fastqc.zip", sample=SAMPLES),
		vcf="genes.vcf"

rule gunzip:
	input: 
		"fastq/{sample}.fq.gz"
	output:
		"fastq/{sample}.fq"
	shell:
		'''
		# Unzipping the fastq files
		gunzip {input} || (echo "gunzip failed" && exit 1)
		
		# Checking if fasta file is divisible by 4
		nr_lines=$(wc -l {output} | cut -d " " -f1)
		result=$(($nr_lines % 4))
		if [ $result -ne 0 ]; then
			echo "Error in gunzip rule: Fastq file {output} is not divisible by 4" >> error_log.txt
			# exit 1
		fi
		'''		

rule fastqc:
	input: 
		fq="fastq/{sample}.fq",
	output: 
		html="fastqc_output/{sample}_fastqc.html",
		fastqc_zip="fastqc_output/{sample}_fastqc.zip",
		summary_txt="fastqc_output/{sample}_fastqc/summary.txt",
		summary_data="fastqc_output/{sample}_fastqc/fastqc_data.txt",
	shell:
		'''
		# Running fastqc on the fastq files
		fastqc -o fastqc_output {input.fq} --extract
		
		# Checking if fastqc produced any FAILs
		if grep -q "FAIL" {output.summary_txt}; then
			echo "Error in fastqc rule: FastQC failed for {wildcards.sample}" >> error_log.txt
			# exit 1
		fi
		'''
		
rule bwa_map:
	input:
		db=genome_db,
		fa="fastq/{sample}.fq"
	output:
		"mapped_reads/{sample}.bam"
	shell:
		'''
		# Mapping the reads to the reference genome
		bwa mem {input} | samtools sort -o {output}
		
		# Quality Control
		# Checks if file exist and has a size greater than 0
		if [ ! -s {output} ]; then
			echo "Error in bwa_map rule: Bam file {output} not created" >> error_log.txt
			# exit 1
		fi
		'''
		
		
rule samtools_index:
	input:
		"mapped_reads/{sample}.bam"
	output:
		"mapped_reads/{sample}.bam.bai"
	shell:
		'''
		# Indexing the bam files
		samtools index {input}
		
		# Checks if file exist and has a size greater than 0
		if [ ! -s {output} ]; then
			echo "Error in samtools_index: Index file {output} not created" >> error_log.txt
			# exit 1
		fi
		'''
        

rule bcftools_call:
	input:
		db = genome_db,
		bam = expand("mapped_reads/{sample}.bam", sample=SAMPLES),
		bai = expand("mapped_reads/{sample}.bam.bai", sample=SAMPLES)
	output:
		report("calls/raw_snps.vcf", category="VCF files")
	shell:
		'''
		# SNP calling using bcftools
		bcftools mpileup -f {input.db} {input.bam} | bcftools call -mv - > {output}
		
		# Checks if file exist and has a size greater than 0
		if [ ! -s {output} ]; then
			echo "Error in bcftools_call rule: VCF file {output} not created" >> error_log.txt
			# exit 1
		fi
		'''


rule snp_cleaning:
	input:
		db = genome_db,
		snps = "calls/raw_snps.vcf"
	output:
		report("calls/clean_snps.vcf", category="VCF files")
	shell:
		'''
		# Decompose, normalize and filter SNPs
		cat {input.snps} | \
		vt decompose - | \
		vt normalize -n -r {input.db} - | \
		vt view -f 'QUAL>20' -h - \
		> {output}
		
		# Checks if file exist and has a size greater than 0
		if [ ! -s {output} ]; then
			echo "Error in snp_cleaning rule: VCF file {output} not created" >> error_log.txt
			# exit 1
		fi
		'''
		

rule snp_annotation:
	input:
		snps = "calls/clean_snps.vcf",
		SNPEFF_JAR = "/lustre1/project/stg_00079/teaching/I0U19a_conda_2024/share/snpeff-5.2-0/snpEff.jar"
	output:
		vcf = report("calls/annotated_snps.vcf", category="VCF files"),
		pie = report("images/impact_pie_chart.png", category="Images"),
		bar = report("images/impact_bar_chart.png", category="Images"),
		txt = report("snpEff_genes.txt", category="snpEff"),
		html = report("snpEff_summary.html", category="snpEff"),
	shell:
		"""
		# Annotate SNPs using SNPeff
		java -Xmx3400m -jar {input.SNPEFF_JAR} eff hg38 -dataDir '/staging/leuven/stg_00079/teaching/snpeff_db' {input.snps} \
		> calls/annotated_snps.vcf
		
		# Checks if file exist and has a size greater than 0
		if [ ! -s {output.vcf} ]; then
			echo 'Error in snp_annotation rule: VCF file {output} not created' >> error_log.txt
			# exit 1 
		fi

		# Creating pie and bar chart images
		python3 ./../plot_graphs.py impact calls/annotated_snps.vcf
		python3 ./../plot_graphs.py functional calls/annotated_snps.vcf
		"""

rule genes_of_interest:
	input: 
		"calls/annotated_snps.vcf"
	output: 
		vcf = report("genes.vcf", category="VCF files"),
		heatmap = report("heatmap.png", category="Images")
	shell:
		"""
		# Selecting all lines with the words 'APP' or 'SOD1' or 'DYRK1A' in the annotated snps file
		grep '#' {input} > {output.vcf}
		grep -i -E '\|APP\||\|SOD1\||\|DYRK1A\|' {input} >> {output.vcf}
		
		# Checks if file exist and has a size greater than 0
		if [ ! -s {output.vcf} ]; then 
			echo 'Error in genes_of_interest rule: VCF file {output} not created' >> error_log.txt
			# exit 1 
		fi

		# Creating heatmap image
		python3 ./../plot_graphs.py heatmap {output.vcf}
		"""
		

		